{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84cf99db-596d-4cbc-bd96-49b35915427c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/smgailab/Allen_AI/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from haystack.telemetry import tutorial_running\n",
    "\n",
    "tutorial_running(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef0243c9-a1f5-4ed0-ba00-6a4a81393aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logging.basicConfig(format=\"%(levelname)s - %(name)s -  %(message)s\", level=logging.WARNING)\n",
    "logging.getLogger(\"haystack\").setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f0d3a02-ac78-4c31-9a50-f3a6b776b1ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please input the URL of your .CSV File: https://s3.eu-central-1.amazonaws.com/deepset.ai-farm-qa/datasets/small_generator_dataset.csv.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.utils.import_utils -  Found data stored in 'test_data'. Delete this first if you really want to fetch new data.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "https://s3.eu-central-1.amazonaws.com/deepset.ai-farm-qa/datasets/small_generator_dataset.csv.zip\n",
      "\n",
      "Fetching file from Dropbox completed.....\n",
      "               title                                               text\n",
      "0  \"Albert Einstein\"  to Einstein in 1922. Footnotes Citations Alber...\n",
      "1  \"Albert Einstein\"  Albert Einstein Albert Einstein (; ; 14 March ...\n",
      "2  \"Albert Einstein\"  observations were published in the internation...\n",
      "3  \"Albert Einstein\"  model for depictions of mad scientists and abs...\n",
      "4     \"Alfred Nobel\"  was adopted as the standard technology for min...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from haystack.utils import fetch_archive_from_http\n",
    "\n",
    "# Download sample\n",
    "doc_dir = \"test_data\"\n",
    "#document_location = \"/home/smgailab/Intel/fastRAG/examples/excel_data\"\n",
    "#drop_box_url = \"https://www.dropbox.com/scl/fi/c1c2h38qtwbkmk1ipstqt/small_generator_dataset.csv.zip?rlkey=xqha1u5ofzpzzcmwa0xu1t0pa&dl=0\"\n",
    "\n",
    "#https://www.dropbox.com/scl/fi/1d9qs31rklpo6rizywhcf/Test_CSV_File.csv.zip?rlkey=lav7u9dvldbgmbfxylmo06x5u&dl=0\n",
    "\n",
    "#\"https://www.dropbox.com/scl/fi/znc9rmaezklw6oyiqqzfx/Test_Template_Allen.csv.zip?rlkey=x1v2xeqz5409u4rruiaykgez9&dl=0\"  Test_Template_Allen\n",
    "\n",
    "#\"https://www.dropbox.com/scl/fi/c1c2h38qtwbkmk1ipstqt/small_generator_dataset.csv.zip?rlkey=xqha1u5ofzpzzcmwa0xu1t0pa&dl=0\" small_generator_dataset\n",
    "\n",
    "# \"https://s3.eu-central-1.amazonaws.com/deepset.ai-farm-qa/datasets/small_generator_dataset.csv.zip\"\n",
    "\n",
    "drop_box_url = input (\"Please input the URL of your .CSV File:\")\n",
    "print()\n",
    "print (drop_box_url)\n",
    "print()\n",
    "fetch_archive_from_http(url=drop_box_url, output_dir=doc_dir)\n",
    "\n",
    "print (\"Fetching file from Dropbox completed.....\")\n",
    "\n",
    "df = pd.read_csv(f\"{doc_dir}/small_generator_dataset.csv\", sep=\",\")\n",
    "\n",
    "# Create dataframe with columns \"title\" and \"text\"\n",
    "#df = pd.read_csv(f\"{doc_dir}/Test_Template_Allen.csv\", sep=\",\")\n",
    "# Minimal cleaning\n",
    "df.fillna(value=\"\", inplace=True)\n",
    "\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "efaa824b-3923-4b8b-bb58-0092dff5d33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack import Document\n",
    "\n",
    "# Use data to initialize Document objects\n",
    "titles = list(df[\"title\"].values)\n",
    "texts = list(df[\"text\"].values)\n",
    "documents = []\n",
    "for title, text in zip(titles, texts):\n",
    "    documents.append(Document(content=text, meta={\"name\": title or \"\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "848e8336-e016-4596-bc91-844b6ecb23a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.document_stores import FAISSDocumentStore\n",
    "\n",
    "document_store = FAISSDocumentStore(faiss_index_factory_str=\"Flat\", return_embedding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3bce8df-6ee1-43c8-b30b-2463e62fb7ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:01<00:00,  1.40it/s]\n",
      "INFO - haystack.modeling.utils -  Using devices: CPU - Number of GPUs: 0\n",
      "INFO - haystack.nodes.retriever.dense -  Init retriever using embeddings of model sentence-transformers/multi-qa-mpnet-base-dot-v1\n",
      "INFO - haystack.modeling.utils -  Using devices: CPU - Number of GPUs: 0\n",
      "INFO - haystack.modeling.utils -  Using devices: CPU - Number of GPUs: 0\n",
      "Loading checkpoint shards: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  2.38it/s]\n",
      "Xformers is not installed correctly. If you want to use memorry_efficient_attention to accelerate training use the following command to install Xformers\n",
      "pip install xformers.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from torch import bfloat16\n",
    "\n",
    "#hf_token=\"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\"\n",
    "\n",
    "model_path = \"/home/smgailab/Intel/fastRAG/Llama-2-7b-chat-hf\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_path) #, use_auth_token=hf_token)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path) #, use_auth_token=hf_token)\n",
    "\n",
    "from haystack.nodes import PromptNode,PromptModel\n",
    "\n",
    "import torch\n",
    "\n",
    "from haystack.nodes import BM25Retriever, SentenceTransformersRanker, EmbeddingRetriever\n",
    "from haystack.nodes import PromptNode, PromptModel\n",
    "from haystack.nodes import PromptNode, PromptTemplate\n",
    "from haystack.nodes import BM25Retriever, SentenceTransformersRanker\n",
    "from haystack.nodes.prompt.invocation_layer import HFLocalInvocationLayer\n",
    "\n",
    "\n",
    "retriever = EmbeddingRetriever(document_store = document_store,\n",
    "                               embedding_model=\"sentence-transformers/multi-qa-mpnet-base-dot-v1\")\n",
    "#retriever = BM25Retriever(document_store=document_store, top_k=100)\n",
    "reranker = SentenceTransformersRanker(model_name_or_path=\"cross-encoder/ms-marco-MiniLM-L-12-v2\", top_k=1)\n",
    "\n",
    "lfqa_prompt = PromptTemplate(name=\"lfqa\",\n",
    "                             prompt_text=\"Answer the question using the provided context. Your answer should be in your own words and be no longer than 50 words. \\n\\n Context: {join(documents)} \\n\\n Question: {query} \\n\\n Answer:\",\n",
    "                             output_parser={\"type\": \"AnswerParser\"}) \n",
    "\n",
    "# exotic configuration based on model_kwargs\n",
    "# inspiration: https://docs.haystack.deepset.ai/docs/prompt_node\n",
    "# using-models-not-supported-in-hugging-face-transformers\n",
    "local_model=PromptModel(\n",
    "    model_name_or_path=\"/home/smgailab/Intel/fastRAG/Llama-2-7b-chat-hf\",\n",
    "    invocation_layer_class=HFLocalInvocationLayer,\n",
    "    model_kwargs={'task_name':'text-generation'}\n",
    "    )\n",
    "\n",
    "prompt = PromptNode(\n",
    "                max_length=1000,\n",
    "                model_name_or_path=local_model,\n",
    "                default_prompt_template=lfqa_prompt,\n",
    "                model_kwargs={#\"model\":model,\n",
    "                              \"tokenizer\":tokenizer,\n",
    "                              #'task_name':\"text2text-generation\",\n",
    "                              'device':None, # placeholder needed to make the underlying HF Pipeline work,\n",
    "                              'model_max_length': 2048, \n",
    "                              \"torch_dtype\": torch.bfloat16,\n",
    "                              'stream':True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ad8f0dc-67c2-4b59-b1fe-7781c087b2d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Writing Documents: 10000it [00:00, 143377.36it/s]                                                                                                                                                                \n",
      "INFO - haystack.document_stores.faiss -  Updating embeddings for 68 docs...\n",
      "Updating Embedding:   0%|                                                                                                                                                              | 0/68 [00:00<?, ? docs/s]\n",
      "Batches:   0%|                                                                                                                                                                             | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Batches:  33%|███████████████████████████████████████████████████████                                                                                                              | 1/3 [00:00<00:01,  1.03it/s]\u001b[A\n",
      "Batches: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:01<00:00,  1.81it/s]\u001b[A\n",
      "Documents Processed: 10000 docs [00:01, 5972.25 docs/s]                                                                                                                                                          \n"
     ]
    }
   ],
   "source": [
    "# Delete existing documents in documents store\n",
    "document_store.delete_documents()\n",
    "\n",
    "# Write documents to document store\n",
    "document_store.write_documents(documents)\n",
    "\n",
    "# Add documents embeddings to index\n",
    "document_store.update_embeddings(retriever=retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d81f0366-ad0e-4813-b495-46e73d170646",
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack import Pipeline\n",
    "p = Pipeline()\n",
    "p.add_node(component=retriever, name=\"Retriever\", inputs=[\"Query\"])\n",
    "p.add_node(component=reranker, name=\"Reranker\", inputs=[\"Retriever\"])\n",
    "p.add_node(component=prompt, name=\"prompt_node\", inputs=[\"Reranker\"])\n",
    "#p.add_node(component=prompt, name=\"prompt_node\", inputs=[\"Retriever\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a74fb20-bceb-448d-b5d3-fc4145a4ec6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 80.03it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Albert Einstein received the first Nobel Prize in Physics in 1921 for his discovery of the law of the photoelectric effect.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = p.run(query=\"who got the first nobel prize in physics\", debug=True)\n",
    "a['answers'][0].answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bc0b4212-baba-4dca-9fb5-22dc93e1e94b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 79.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Query: who got the first nobel prize in physics'\n",
      "'Answers:'\n",
      "[   {   'answer': ' Albert Einstein received the first Nobel Prize in Physics '\n",
      "                  'in 1921 for his discovery of the law of the photoelectric '\n",
      "                  'effect.'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 79.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Query: When iphone XS was launched?'\n",
      "'Answers:'\n",
      "[{'answer': ' The iPhone XS was launched on September 12, 2018.'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 75.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Query: when is the next deadpool movie being released'\n",
      "'Answers:'\n",
      "[   {   'answer': ' There is no next Deadpool movie being released as Akira '\n",
      "                  \"Kurosawa's estate has assigned the remake rights to most of \"\n",
      "                  'his movies and unproduced screenplays to the L.A.-based '\n",
      "                  'company Splendent, which aims to introduce a new generation '\n",
      "                  'of moviegoers to these unforgettable stories.'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 63.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Query: which mode is used for short wave broadcast service'\n",
      "'Answers:'\n",
      "[{'answer': ' Single sideband (SSB) is used for short wave broadcast service.'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 76.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Query: who is the owner of reading football club'\n",
      "'Answers:'\n",
      "[   {   'answer': ' Reading Football Club is not one of the grounds used for '\n",
      "                  'Test cricket in England and Wales.'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 74.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Query: when is the next scandal episode coming out'\n",
      "'Answers:'\n",
      "[   {   'answer': ' The next episode of the popular TV show \"Scandal\" is '\n",
      "                  'expected to air in 2027, at the earliest, given the recent '\n",
      "                  'news that the show will not be renewed for another season.'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 66.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Query: when is the last time the philadelphia won the superbowl'\n",
      "'Answers:'\n",
      "[   {   'answer': ' The Philadelphia Eagles have never won a Super Bowl. The '\n",
      "                  'last time they won a championship was in 1960, when they '\n",
      "                  'were known as the Philadelphia Eagles and won the NFL '\n",
      "                  'Championship Game.'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 23.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Query: what is the most current adobe flash player version'\n",
      "'Answers:'\n",
      "[   {   'answer': ' The most current Adobe Flash Player version available for '\n",
      "                  'Apple TV is version 32.0.0.188.'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 62.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Query: how many episodes are there in dragon ball z'\n",
      "'Answers:'\n",
      "[{'answer': ' There are 291 episodes in Dragon Ball Z.'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 73.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Query: what is the first step in the evolution of the eye'\n",
      "'Answers:'\n",
      "[   {   'answer': ' The first step in the evolution of the eye is believed to '\n",
      "                  'be the development of light-sensitive pigments, such as '\n",
      "                  'rhodopsin, in simple organisms around 1 billion years ago.'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 64.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Query: where is gall bladder situated in human body'\n",
      "'Answers:'\n",
      "[   {   'answer': ' The gallbladder is situated in the upper right quadrant of '\n",
      "                  'the abdomen, beneath the liver.'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 52.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Query: what is the main mineral in lithium batteries'\n",
      "'Answers:'\n",
      "[   {   'answer': ' Spodumene is the most important mineral used in lithium '\n",
      "                  'batteries.'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 55.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Query: who is the president of usa right now'\n",
      "'Answers:'\n",
      "[   {   'answer': ' The current President of the United States of America is '\n",
      "                  'Joe Biden.'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 16.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Query: where do the greasers live in the outsiders'\n",
      "'Answers:'\n",
      "[   {   'answer': ' The greasers live in the poorer part of Tulsa, Oklahoma, '\n",
      "                  'known as the \"outhside\".'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 54.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Query: panda is a national animal of which country'\n",
      "'Answers:'\n",
      "[{'answer': ' Azerbaijan'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 49.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Query: what is the name of manchester united stadium'\n",
      "'Answers:'\n",
      "[{'answer': ' Old Trafford.'}]\n"
     ]
    }
   ],
   "source": [
    "from haystack.utils import print_answers\n",
    "\n",
    "QUESTIONS = [\n",
    "    \"who got the first nobel prize in physics\",\n",
    "    \"When iphone XS was launched?\",\n",
    "    \"when is the next deadpool movie being released\",\n",
    "    \"which mode is used for short wave broadcast service\",\n",
    "    \"who is the owner of reading football club\",\n",
    "    \"when is the next scandal episode coming out\",\n",
    "    \"when is the last time the philadelphia won the superbowl\",\n",
    "    \"what is the most current adobe flash player version\",\n",
    "    \"how many episodes are there in dragon ball z\",\n",
    "    \"what is the first step in the evolution of the eye\",\n",
    "    \"where is gall bladder situated in human body\",\n",
    "    \"what is the main mineral in lithium batteries\",\n",
    "    \"who is the president of usa right now\",\n",
    "    \"where do the greasers live in the outsiders\",\n",
    "    \"panda is a national animal of which country\",\n",
    "    \"what is the name of manchester united stadium\",\n",
    "]\n",
    "\n",
    "for question in QUESTIONS:\n",
    "    res = p.run(query=question)\n",
    "    print_answers(res, details=\"minimum\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e16e2629-1a2c-4206-9fbb-b98817305795",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_491597/2034676420.py:50: GradioDeprecationWarning: Usage of gradio.inputs is deprecated, and will not be supported in the future, please import your component from gradio.components\n",
      "  inputs = gr.inputs.Textbox(label=\"Question\"),\n",
      "/tmp/ipykernel_491597/2034676420.py:50: GradioDeprecationWarning: `optional` parameter is deprecated, and it has no effect\n",
      "  inputs = gr.inputs.Textbox(label=\"Question\"),\n",
      "/tmp/ipykernel_491597/2034676420.py:50: GradioDeprecationWarning: `numeric` parameter is deprecated, and it has no effect\n",
      "  inputs = gr.inputs.Textbox(label=\"Question\"),\n",
      "/tmp/ipykernel_491597/2034676420.py:51: GradioDeprecationWarning: Usage of gradio.outputs is deprecated, and will not be supported in the future, please import your components from gradio.components\n",
      "  outputs = gr.outputs.Textbox(label=\"Answer\"),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 21.57it/s]\n",
      "Batches: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 18.49it/s]\n",
      "Batches: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 56.46it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 57\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;66;03m#answers = print_answers (result)\u001b[39;00m\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output\n\u001b[1;32m     49\u001b[0m \u001b[43mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mInterface\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[43m            \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTextbox\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mQuestion\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[43m            \u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTextbox\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mAnswer\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[43m            \u001b[49m\u001b[43mexamples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mQUESTIONS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdescription\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mBase Model: Llama-2-7b-chat-hf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m#outputs = \"text\",\u001b[39;49;00m\n\u001b[1;32m     55\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtitle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtitle\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[43m                  \u001b[49m\n\u001b[0;32m---> 57\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlaunch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshare\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Allen_AI/lib/python3.11/site-packages/gradio/blocks.py:1998\u001b[0m, in \u001b[0;36mBlocks.launch\u001b[0;34m(self, inline, inbrowser, share, debug, enable_queue, max_threads, auth, auth_message, prevent_thread_lock, show_error, server_name, server_port, show_tips, height, width, encrypt, favicon_path, ssl_keyfile, ssl_certfile, ssl_keyfile_password, ssl_verify, quiet, show_api, file_directories, allowed_paths, blocked_paths, root_path, _frontend, app_kwargs)\u001b[0m\n\u001b[1;32m   1996\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1997\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshare_url \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1998\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshare_url \u001b[38;5;241m=\u001b[39m \u001b[43mnetworking\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msetup_tunnel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1999\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mserver_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mserver_port\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshare_token\u001b[49m\n\u001b[1;32m   2000\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2001\u001b[0m     \u001b[38;5;28mprint\u001b[39m(strings\u001b[38;5;241m.\u001b[39men[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSHARE_LINK_DISPLAY\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshare_url))\n\u001b[1;32m   2002\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (quiet):\n",
      "File \u001b[0;32m~/Allen_AI/lib/python3.11/site-packages/gradio/networking.py:190\u001b[0m, in \u001b[0;36msetup_tunnel\u001b[0;34m(local_host, local_port, share_token)\u001b[0m\n\u001b[1;32m    186\u001b[0m     remote_host, remote_port \u001b[38;5;241m=\u001b[39m payload[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhost\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;28mint\u001b[39m(payload[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mport\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    187\u001b[0m     tunnel \u001b[38;5;241m=\u001b[39m Tunnel(\n\u001b[1;32m    188\u001b[0m         remote_host, remote_port, local_host, local_port, share_token\n\u001b[1;32m    189\u001b[0m     )\n\u001b[0;32m--> 190\u001b[0m     address \u001b[38;5;241m=\u001b[39m \u001b[43mtunnel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart_tunnel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    191\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m address\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/Allen_AI/lib/python3.11/site-packages/gradio/tunneling.py:59\u001b[0m, in \u001b[0;36mTunnel.start_tunnel\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstart_tunnel\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdownload_binary()\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39murl \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_start_tunnel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBINARY_PATH\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39murl\n",
      "File \u001b[0;32m~/Allen_AI/lib/python3.11/site-packages/gradio/tunneling.py:95\u001b[0m, in \u001b[0;36mTunnel._start_tunnel\u001b[0;34m(self, binary)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproc\u001b[38;5;241m.\u001b[39mstdout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m---> 95\u001b[0m line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstdout\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m line \u001b[38;5;241m=\u001b[39m line\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstart proxy success\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m line:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "title = \"Generative QA with RAGenerator (With Haystack) with LLMs - Questions And Answers with Intel Xeon 4th Gen Processor\"\n",
    "\n",
    "#question = \"who got the first nobel prize in physics\"\n",
    "\n",
    "#results = pipe.run(query=question, params={\"Generator\": {\"top_k\": 1}, \"Retriever\": {\"top_k\": 1}})\n",
    "#results = pipe.run(query=question)\n",
    "#print_answers(results, details=\"minimum\")\n",
    "\n",
    "\n",
    "TEMPLATE = [\n",
    "    \"Intel is founded by who and in which year?\",\n",
    "    \"Who is Intel's competitors in PC chupsets?\",\n",
    "    \"What is the name of Intel first microprocessor and in which year?\",\n",
    "    \"Which year Intel opened its first international manufacturing facility and where?\",\n",
    "    \"When did Intel announced Pat Gelsinger as new Intel CEO?\",\n",
    "    \"When Broadcom announced an agreement to acquire VMware and how much?\",\n",
    "    \"At which year was VMware founded and by who?\",\n",
    "    \"Who was appointed as the CEO of VMWare in August 2012?\",\n",
    "    \"Which year did VMware launced its own Iaas service?\",\n",
    "    \"When did Gelsinger become the CEO of VMware?\",\n",
    "    \"When was VMware Workstation introduced?\",\n",
    "    \"What is VMware ESXi?\",\n",
    "    \"What is name the open-source platform-as-a-service and which year?\",\n",
    "    \"What is VMware's most notable products?\",\n",
    "    \"When IBM acquire Red Hat and for how much?\",\n",
    "    \"When do RedHat went on public?\",\n",
    "    \"Tell me about Cygnus Solutions?\",\n",
    "    \"When IBM announced to acquire Red Hat?\",\n",
    "    \"Tell me about Red Hat\",\n",
    "    \"Which year Red Hat became the first one-billion dollar open source company?\",\n",
    "    \"what is the first step in the evolution of the eye\",\n",
    "    \"where is gall bladder situated in human body\",\n",
    "\n",
    "]\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "def predict (question):\n",
    "    results = p.run(query=question,debug=True)\n",
    "    output = results['answers'][0].answer\n",
    "    #answers = print_answers (result)\n",
    "    return output\n",
    "\n",
    "   \n",
    "gr.Interface (fn=predict,\n",
    "            inputs = gr.inputs.Textbox(label=\"Question\"),\n",
    "            outputs = gr.outputs.Textbox(label=\"Answer\"),\n",
    "            examples=QUESTIONS,\n",
    "            description = \"Base Model: Llama-2-7b-chat-hf\",\n",
    "            #outputs = \"text\",\n",
    "            title=title\n",
    "                  \n",
    "            ).launch(share=True)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87c7d48-c116-4c2c-bfb7-4a5bf1fd1c47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a0fb99-4f33-4ef6-badf-d29b7dc869da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2793464-fd59-434c-bbf0-99f37a56e80b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
